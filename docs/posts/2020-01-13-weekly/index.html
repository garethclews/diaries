<!DOCTYPE html>
<html>

<head>
    
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">
<meta name="description" content="&lt;3">
<title>
Bad Men - the fishman diaries
</title>











<link rel="stylesheet" href="/diaries/css/main.min.81bbafc4df93b11c1c3e2449464373c384aa4903731b4fc7a77dfcdd979e184f.css" integrity="sha256-gbuvxN&#43;TsRwcPiRJRkNzw4SqSQNzG0/Hp3383ZeeGE8=" crossorigin="anonymous" media="screen">



 

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Didact+Gothic">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Bad Men"/>
<meta name="twitter:description" content="13 January 2020, weekly newsletter"/>

<meta property="og:title" content="Bad Men" />
<meta property="og:description" content="13 January 2020, weekly newsletter" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://karetsu.github.io/diaries/posts/2020-01-13-weekly/" />
<meta property="article:published_time" content="2020-01-13T05:00:00+00:00" />
<meta property="article:modified_time" content="2020-01-13T05:00:00+00:00" />


    

    
    
    
    <title>
        
        Bad Men
        
    </title>
</head>

<body>
    <div class="wrap">
        <div class="section" id="title">Bad Men</div>

        
<div class="section" id="content">
    Jan 13, 2020 &#183; 420 words
    
    <hr/>
    

<p>A quiet week to start the year off. Wading through a fair share of &lsquo;best of&rsquo;
collections only one has made it as far as this week&rsquo;s post!</p>

<h2 id="post-of-the-week">Post of the Week</h2>

<p>It sounds awfully grand, but the <em>New Renaissance</em> is an interesting topic in
<a href="https://www.forbes.com/sites/cognitiveworld/2020/01/05/2020-will-bring-a-new-renaissance-humanity-over-technology/">an
article</a>
by Gerd Leonhard (a very popular futurist). I won&rsquo;t attempt to summarise it here
because its short enough already and I think you should go read it.</p>

<h2 id="blogs-and-commentary">Blogs and commentary</h2>

<ul>
<li>I do enjoy a good &lsquo;best visualisations of&hellip;&rsquo; post and <a href="https://flowingdata.com/2019/12/19/best-data-visualization-projects-of-2019">2019 doesn&rsquo;t let me
down</a>.
Here is just one of the examples, made using R.
<figure>
    <img src="https://www.data-imaginist.com/art/005_genesis/genesis4321.png" width="100%"/> <figcaption>
            <h4>Generative aRt</h4>
        </figcaption>
</figure>
</li>
<li>Towards Data Science have a pretty good summary of the most important bits of
maths you need to know from <a href="https://towardsdatascience.com/machine-learning-necessary-for-deep-learning-2095a345ec2c">machine learning which are necessary for deep
learning</a>
including things like Killback-Leibler divergence, point estimators and
maximum likelihood estimation.</li>
<li>Of all possible &lsquo;mis-wirings&rsquo; of the human brain I think that Synesthesia is
the coolest. Being able to &lsquo;see&rsquo; sounds is pretty cool. Now, Jun Wu puts
forward the case that it <a href="https://towardsdatascience.com/synesthesia-an-inspiring-condition-for-ai-researchers-10cd57708855">should inspire the next tranche of AI
research</a>.</li>
<li>I <i class="tf-ion-heart"></i> <a href="http://mathworld.wolfram.com/GaugeTheory.html">gauge
theory</a>, so adding it into CNNs
in &lsquo;gauge-equivariant CNNs&rsquo; makes me pretty happy. These extend the ability of
learning past 2 dimension which may allow <a href="https://www.quantamagazine.org/an-idea-from-physics-helps-ai-see-in-higher-dimensions-20200109/">deep learning on curved
surfaces</a>
to start being a real thing.</li>
</ul>

<h2 id="papers">Papers</h2>

<ul>
<li>Machine learning is getting its groove on even in <a href="http://proceedings.mlr.press/v97/mendis19a/mendis19a.pdf">compiler
optimisation</a> these
days. It doesn&rsquo;t seem to be much fancier than an RNN with LSTM components. I&rsquo;m
interested in picking this apart to understand the cases where code becomes
less optimal but that might be a ways away yet.</li>
</ul>

<h2 id="tools-of-the-trade">Tools of the trade</h2>

<p>Starting off more generically:</p>

<ul>
<li>Put the Dask down! Time to try <a href="https://ray.io/">ray</a>.</li>
<li>fast.ai have published a <a href="https://www.fast.ai/2020/01/07/data-questionnaire/">data
questionnaire</a> to help you
tackle the common problems in data projects.</li>
</ul>

<p>Two types of propaganda this week!</p>

<h4 id="julia-propaganda">Julia propaganda</h4>

<ul>
<li><a href="http://pages.stat.wisc.edu/~bates/JuliaForRProgrammers.pdf">Julia for R
programmers</a> may
only be a presentation but it does a very good job of showcasing the
similarities and differences between the two. It even has some examples of
using the Distributions package, interfacing with BLAS and LAPACK (linear
algebra) libraries and performing a ridge regression.</li>
</ul>

<h4 id="haskell-propaganda">Haskell propaganda</h4>

<ul>
<li>Category theory has become a really useful for writing elegant and
maintainable code. MIT have a <a href="http://brendanfong.com/programmingcats.html">&lsquo;from scratch&rsquo;
course</a> to show you how great
they are.</li>
<li>Lenses are ace. Go <a href="https://www.schoolofhaskell.com/school/to-infinity-and-beyond/pick-of-the-week/a-little-lens-starter-tutorial">find out
more</a>.</li>
</ul>

<h2 id="origin-of-the-title">Origin of the title</h2>

<blockquote>
<p>Bad men need nothing more to compass their end, than that good men look on and
do nothing</p>
</blockquote>

<p>&ndash; John Stuart Mill</p>

</div>


        
<div class="section bottom-menu">
    

    
        <a href="/diaries/posts">back</a>
        
    

    
</p>
</div>


        <div class="section footer"></div>
    </div>
</body>

</html>