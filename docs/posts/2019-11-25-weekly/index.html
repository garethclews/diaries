<!DOCTYPE html>
<html>

<head>
    
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">
<meta name="description" content="&lt;3">
<title>
Party all the time - the fishman diaries
</title>











<link rel="stylesheet" href="/diaries/css/main.min.81bbafc4df93b11c1c3e2449464373c384aa4903731b4fc7a77dfcdd979e184f.css" integrity="sha256-gbuvxN&#43;TsRwcPiRJRkNzw4SqSQNzG0/Hp3383ZeeGE8=" crossorigin="anonymous" media="screen">



 

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Didact+Gothic">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Party all the time"/>
<meta name="twitter:description" content="25 November 2019, guest newsletter"/>

<meta property="og:title" content="Party all the time" />
<meta property="og:description" content="25 November 2019, guest newsletter" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://karetsu.github.io/diaries/posts/2019-11-25-weekly/" />
<meta property="article:published_time" content="2019-11-25T09:00:00+00:00" />
<meta property="article:modified_time" content="2019-11-25T09:00:00+00:00" />


    

    
    
    
    <title>
        
        Party all the time
        
    </title>
</head>

<body>
    <div class="wrap">
        <div class="section" id="title">Party all the time</div>

        
<div class="section" id="content">
    Nov 25, 2019 &#183; 362 words
    
    <hr/>
    

<p>Time is limited this week, so expect a rushed description of the content, but it
is still better than no content!</p>

<h2 id="post-of-the-week">Post of the week</h2>

<p>I&rsquo;m not convinced that this isn&rsquo;t because of personal bias toward the current
considerations of the applications of machine learning but I very much enjoyed
reading a presentation from Arvind Narayanan from Princeton University.</p>

<p>Comparing companies selling &lsquo;AI&rsquo; (cf. last week&rsquo;s post) with the <a href="https://en.wikiquote.org/wiki/Snake_oil">snake oil
salesmen</a> is something I have done for
quite some time now, but Arvind gives some ways to <a href="https://www.cs.princeton.edu/~arvindn/talks/MIT-STS-AI-snakeoil.pdf">recognise AI snake
oil</a>.</p>

<h2 id="blogs-and-commentary">Blogs and commentary</h2>

<ul>
<li>Narrowly missing out on my top post, but also suggested to me by Huw, is a
medium post on how to deal with doing <a href="https://towardsdatascience.com/data-science-is-boring-1d43473e353e">data science in the
wild</a> and
how to mitigate the humdrum nature of not being a university researcher and
containing suggestions on how to beat the boredom.</li>
<li>Technically about marketing, I quite enjoyed <a href="https://marketoonist.com/2019/11/kpi-overload.html">this
post&rsquo;s</a> imagery and felt
that it very well summed up people&rsquo;s obsession with dashboards!</li>
<li>Wired led with an opinion piece on applications of &lsquo;AI for good&rsquo; and how they
are often <a href="https://www.wired.com/story/opinion-ai-for-good-is-often-bad/">actually
bad</a>.</li>
<li>The <a href="https://pytorch.org/deep-learning-with-pytorch">Deep Learning with
PyTorch</a> book has been made
free. Go grab a copy!</li>
<li>Uber have generated some <a href="https://eng.uber.com/3d-tiles-loadersgl/">fancy 3D city
visualisations</a>. They&rsquo;re pretty and
something pretty cool.</li>
</ul>

<h2 id="papers">Papers</h2>

<p>I&rsquo;ve only read one paper this week. I went back and revisited the original paper
on <a href="https://arxiv.org/pdf/1312.6114.pdf">variational autoencoders</a> to help me
out with the implementation below.</p>

<h2 id="functional-programming-propaganda">Functional programming propaganda</h2>

<ul>
<li>I quite enjoyed seeing a Haskell, from scratch <a href="https://www.declanoller.com/2019/11/15/variational-autoencoders-in-haskell-or-how-i-learned-to-stop-worrying-and-turn-my-friends-into-dogs/">implementation of a
variational
autoencoder</a>.
So much so that I will be doing something similar myself. I&rsquo;m not sure if you
could really pass the pictures of their friends off as genuine dog photos but
with a latent space of only two dimensions its still really good!</li>
<li>Michael Snoyman is a prolific writer about all things Haskell. This time he
has written a <a href="https://www.snoyman.com/blog/2019/11/boring-haskell-manifesto">Boring Haskell
Manifesto</a> to
help people to get Haskell into their organisation.</li>
</ul>

<h2 id="origin-of-the-title">Origin of the title</h2>

<p>Spotify recommended me a modern cover of this &ldquo;classic&rdquo; and it has been in my
head since (for those interested the new one is by a band called Thank You Scientist)

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/iWa-6g-TbgI" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>
</p>

</div>


        
<div class="section bottom-menu">
    

    
        <a href="/diaries/posts">back</a>
        
    

    
</p>
</div>


        <div class="section footer"></div>
    </div>
</body>

</html>