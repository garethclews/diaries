---
title: "Said the King to the River"
date: 2020-01-20T05:00:00Z
draft: false
author: aloysius
image: images/logo.jpg
description: "20 January 2020, weekly newsletter"
---

2020's content is finally coming through. Lots of fun and intereting things to
bring my brain slowly out of its slumber.


## Post of the week

Not something I found interesting so much as terrifying. The [Defense and
Security
Accelerator](https://www.gov.uk/government/news/revolutionary-artificial-intelligence-warship-contracts-announced)
has announced contracts worth Â£4M to use 'artificial intelligence' in warships.
Given how terrible AI is at playing war video games are we really pushing it into
machines which can define the fates of nations? Yes. Yes we are.

You should take this with a pinch of salt. I'm conflating the reality of the
matter and I imagine the use is far more mundane. The thought of it is still
very skynet though!


## Blogs and commentary

MIT's deep learning series starts our year with a good description of what the
current state of the art in deep learning is and the hopes for 2020.

{{< youtube 0VH1Lim8gL8 >}}


Towards Data Science have had a very, very busy start to the year.

- [Making use of time
  features](https://towardsdatascience.com/its-official-time-doesn-t-exist-8c786530eca1),
  in which you may learn a little physics.
- [Deep learning in brain-computer
  interface](https://towardsdatascience.com/deep-learning-in-brain-computer-interface-f650d00268d0)
  which is as futuristic as your favourite sci-fi novella.
- A description of Uber's [deep learning
  stack](https://towardsdatascience.com/uber-has-been-quietly-assembling-one-of-the-most-impressive-open-source-deep-learning-stacks-in-b645656ddddb)
  and how it is one of the best.
- Finally, a step back from the edge to provide a tutorial for [understanding
  neural
  networks](https://towardsdatascience.com/under-the-hood-of-deep-learning-e8bb39aec5d2).


Other posts from around the web:

- Nature feature a description of how hardware can evolve to [improve machine
  learning capabilities of modern
  computers](https://www.nature.com/articles/d41586-020-00002-x). The paper is
  expensive to purchase so I haven't read it.
- Microsoft made me happy (shocking I know) by pledging to become
  ['carbon negative'](https://www.bbc.com/news/technology-51133811) by 2050.
- I've previously posted blogs from Vicki Boykis so sticking with this tradition
  we have [AI won't save
  healthcare](https://vicki.substack.com/p/ai-wont-save-healthcare).
  She has become one of my favourite voices in the machine learning world.
- Tristan Handy (of data science roundup fame) has written a blog about the
  [changing landscape of
  analytics](https://blog.getdbt.com/analytics-engineering-for-everyone/?utm_campaign=The%20Data%20Science%20Roundup&utm_medium=email&utm_source=Revue%20newsletter).
  The central dysfunction of data section, in particular, felt very familiar to
  me through a lot of conversations I've had across government and industry.
  Please use this full url as it refers via Tristan's newsletter.
- DeepMind found a deep learning technique also works [in human
  brains](https://www.newscientist.com/article/2230327-deepmind-found-an-ai-learning-technique-also-works-in-human-brains/).
- El Reg has their first [AI
  roundup](https://www.theregister.co.uk/2020/01/13/ai_roundup_100120/) of 2020.
  Including a link to a post on how machine learning is helping to drive [bad
  decisions in
  Hollywood](https://www.bleedingcool.com/2020/01/11/warner-bros-outsourcing-decisions-to-greenlight-new-films-to-ai-doubles-down-on-worst-hollywood-instincts/).
- This one is worth a look if just for the gif at the top! Via boingboing, we
  have [when machine learning
  cheats](https://boingboing.net/2020/01/11/optimizers-curse.html).
- Following up on a previous post describing how Shakespeare's _Henry VIII_ was
  probably about half written by John Fletcher is a discourse on how ML can
  [change the way we read Shakespeare](https://reaction.life/could-ai-revolutionise-how-we-read-shakespeare).


## Propaganda

- Lenses are amazing. I've talked about them previously but this week, here's
  your chance to [dig into the library](https://deontologician.com/wiki/lenses/)
  a little bit.
- Cabal is my favourite build tool. Well, when I couple it with nix it is
  anyway. Go find out a little more about it and some of its
  [features](https://vrom911.github.io/blog/common-stanzas).
- Way back before Halloween I posted a [math3ma
  blog](https://blog.jle.im/entry/foldl-adjunction.html) about adjunctions.
  Junstin Le now brings more practicality to this idea by considering
  [adjunctions in the wild](https://blog.jle.im/entry/foldl-adjunction.html) and
  in particular looking at `foldl`.
- I've started an audit on the coursera [Julia Scientific
  Programming](https://www.coursera.org/learn/julia-programming) course. I've
  found the first week more elementary than I need but I'm looking forward to
  the rest. I'm working through the videos without touching the notebooks and
  writing my own .jl files and its definitely proving worth it. Give it a go if
  you're interested in learning some Julia, its free after all!


## Origin of the Title

La Dispute are touring and I can't wait to see them.

{{< youtube J5UiE_MWm2k >}}
