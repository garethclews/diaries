---
title: "The whole thing starts with a box"
date: 2019-12-16T07:00:00Z
draft: true
author: aloysius
image: images/logo.jpg
description: "16 December 2019, weekly newsletter"
---

## Post of the Week

As 2019 is coming to an end we can expect to see plenty of 'best of the year'
type posts but the one I've enjoyed the most so far is [re•work's 30 influential
videos of
2019](https://blog.re-work.co/30-pieces-of-influential-ai-research-in-2019/).

I haven't been able to make time to watch them but of the ones I have so far I
have enjoyed the experience. This will be the last one of these posts until the
new year so that I can spend Christmas down-time dealing with the many
[issues](https://github.com/karetsu/diaries/issues), if you wish to spread the
holiday spirit then please feel free to PR and MR!


## Blogs and commentary
:LOGBOOK:
CLOCK: [2019-12-15 Sun 23:24]
CLOCK: [2019-12-15 Sun 23:23]--[2019-12-15 Sun 23:24] =>  0:01
CLOCK: [2019-12-15 Sun 23:23]--[2019-12-15 Sun 23:23] =>  0:00
:END:

- A good talk by Will Kurt (of [Count Bayesie](https://www.countbayesie.com)
  fame) introducing probability for programmers. The blurb will tell you that
  the talk 'attempts to cover all of statistics in 90 minutes' and whilst that
  is really impossible it goes from 0 to generalised linear models which is
  actually pretty nifty.
  {{< youtube uWZggtv85CU >}}
- Sticking on a mathematical theme, a recent paper equates learnability
  uncertainty with some of Gödel's most famous work. That if the [continuum
  hypothesis](https://en.wikipedia.org/wiki/Continuum_hypothesis) is true then a
  small sample is sufficient to make an extrapoloation (i.e. prediction) but if
  it is false then no amount of training data is ever sufficient to make
  accurate estimates. This won't have any real effect on applications of machine
  learning but should help to drive home the fact that something which is
  heavily reliant on mathematics also comes a cropper of the same limitations.
  Only now we have a formal proof of it.
- Having recently re-watched The Wolf of Wall Street I found that the current
  [truth of market
  traders](https://www.forbes.com/sites/jackkelly/2019/12/10/artificial-intelligence-is-superseding-well-paying-wall-street-jobs/#43483517524d)
  is a far more sterile affair. Traders seem to be no more, replaced by
  algorithms which is far further ahead of the game than most jobs I think.
- Rice University have created a new model which claims to provide [exponential
  gain for linear cost during
  training](https://arstechnica.com/gadgets/2019/12/mach-ai-training-linear-cost-exponential-gain/).
  I'm not sure if I believe it yet outside of a carefully crafted test case but
  we shall have to wait and see.
- Yoshua Bengio in an
  [interview](https://spectrum.ieee.org/tech-talk/robotics/artificial-intelligence/yoshua-bengio-revered-architect-of-ai-has-some-ideas-about-what-to-build-next)
  about how general intelligence might end up being a very complicated mish mash
  of technologies built on top of each other and how he believes that's ok.
  The [AI Index
  Report](https://www.theverge.com/2019/12/12/21010671/ai-index-report-2019-machine-learning-artificial-intelligence-data-progress)
  suggests that general intelligence is still a very long way away, which
  supports the statements made by Bengio.
- Also from Bengio, a [sobering message about the future of
  AI](https://www.wired.com/story/sobering-message-future-ai-party/#). Not
  necessarily contradictory to the previous post but a statement that simply
  throwing more grunt at the problem won't solve the real problems faced for
  those working toward general intelligence.
- The Finnish Presidency of the Council of the EU has decided to invest in
  people’s future skills and will make the [Elements of
  AI](https://www.elementsofai.com/eu2019fi) online course freely available in
  all official EU languages. English is now available! I wish this could give
  me an excuse to visit Finland but the chances are slim.
- The free press have started to pick up interviews with leading experts [to
  curb decisions created by biased
  AI](https://www.theguardian.com/technology/2019/dec/12/ai-end-uk-use-racially-biased-algorithms-noel-sharkey).
  This follows on from last week's post about the ICO and ATI consultation and
  it seems that there is growing fervour around explicability.
- Harvard Business Review talk about [the AI transparency
  paradox](https://hbr.org/2019/12/the-ai-transparency-paradox). I don't think
  that this truly is a paradox so much as when providing more information about
  the inner workings you open yourself up to attacks and when you disclose or
  seek to understand less you can't be sure of why it has made a decision. Still
  a valid point though.

## Papers

- Google Brain's [latest paper](https://arxiv.org/pdf/1912.01603.pdf) introduces
  its Dreamer model. Reinforcement learning now has an 'imagination' to predict
  how things work.


## Tools of the trade

This week is Julia heavy, which gives away the things I have mostly been doing!

- Solve [nonlinear eigenvalue
  problems](https://nep-pack.github.io/NonlinearEigenproblems.jl/) with Julia.
- Also Julia, [statically sized
  arrays](https://github.com/JuliaArrays/StaticArrays.jl).
- Need a dependency-free Julia alternative to
  [readxl](https://readxl.tidyverse.org/)? Try
  [XLSX.jl](https://github.com/felipenoris/XLSX.jl).
- Last week I mentioned Frank McSherry's latest effort in making timely dataflow
  work by joining Materialize. This has been picked up in various other
  newsletters this week and even has [a talk about
  it](https://www.datacouncil.ai/talks/the-materialize-incremental-view-maintenance-engine).
  Gathering steam behind this idea means we could be moving into territory where its usable by mere mortals!




## Origin of the title

Last week I went to see A Nightmare Before Christmas live. It was phenomenal.
Here's the song that the lyric is taken from.

{{< youtube jAHXzDUT9hs >}}
